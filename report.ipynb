{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyNaiveBayesClassifier, MyDecisionTreeRandomForestClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.class_utils\n",
    "importlib.reload(mysklearn.class_utils)\n",
    "import mysklearn.class_utils as class_utils\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✈️ Flight Delay Classification ✈️\n",
    "### Authors: Izzy May and Drew Fitzpatrick\n",
    "### Course: CPSC 322, Fall 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Flight delays are a critical concern in aviation, impacting passengers, airlines, and airport operations. In this project, we aim to predict flight delays based on various flight-related attributes using three classification algorithms: Naive Bayes (dt), Decision Tree, and Random Forest.  \n",
    "\n",
    "1. **Naive Bayes (dt):** A probabilistic model assuming feature independence.\n",
    "2. **Decision Tree:** A non-linear classifier that splits data into decision-based regions.\n",
    "3. **Random Forest:** An ensemble method combining multiple decision trees to improve robustness and accuracy.\n",
    "\n",
    "Our dataset is from [Kaggle](#https://www.kaggle.com/code/farzadnekouei/flight-data-eda-to-preprocessing). It is a csv file containing flight information, with attributes such as departure/arrival times, airline, origin, destination, the time spent in the air, and the date.\n",
    "\n",
    "To perform the classification, we categorized delays into six groups based on delay duration:\n",
    "\n",
    "- 0: No delay or early arrival.\n",
    "- 1: Delay up to 30 minutes.\n",
    "- 2: Delay between 31-60 minutes.\n",
    "- 3: Delay between 61-120 minutes.\n",
    "- 4: Delay between 121-180 minutes.\n",
    "- 5: Delay exceeding 180 minutes.\n",
    "\n",
    "Using 10-fold cross-validation to ensure comprehensive and generalizable performance metrics, we evaluate the performance of these classifiers based on metrics such as accuracy, precision, recall, F1-score, and confusion matrices.\n",
    "\n",
    "### Findings Overview\n",
    "Preliminary results from the classification task indicate that:\n",
    "\n",
    "- **k-Nearest Neighbor** shows the best performance with the highest accuracy (0.63), precision (0.58), recall (0.68), and F1 score (0.62), along with relatively strong recognition percentages across all categories.\n",
    "- **Random Forest** shows moderate performance with an accuracy of 0.43, precision of 0.48, recall of 0.42, and an F1 score of 0.43, indicating better performance than Naive Bayes but still lower than kNN.\n",
    "- **Naive Bayes** has the lowest performance, with an accuracy of 0.22, precision of 0.37, recall of 0.36, and an F1 score of 0.36, reflecting poor recognition across all categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "The dataset used for this project consists of flight information, originally sourced from Kaggle, and preprocessed to facilitate the prediction of flight delays. Below is an overview of the dataset:\n",
    "\n",
    "1. **Balancing:** The cleaned dataset, balanced_flights.csv, contains flight information balanced for analytical purposes and to maintain the integrity of the predictive models. The original dataset with over 337,000 instances was balanced by randomly selecting attributes to ensure even representation across delay categories:\n",
    "    - 0 (On Time): 300 instances\n",
    "    - 1 (0–30 mins): 300 instances\n",
    "    - 2 (30–60 mins): 300 instances\n",
    "    - 3 (1–2 hours): 300 instances\n",
    "    - 4 (2–3 hours): 300 instances\n",
    "    - 5 (Over 3 hours): 300 instances\n",
    "\n",
    "2. **Features:** \n",
    "- Time-based Attributes: year, month, day, hour, minute, dep_time, and sched_dep_time.\n",
    "- Operational Attributes: carrier, flight, and tailnum.\n",
    "- Location and Flight Characteristics: origin, dest, distance, and air_time.\n",
    "- Delay Attributes: dep_delay and arr_delay (categorized into delay categories as the target variable).\n",
    "\n",
    "4. **Classification Target Features:**\n",
    "- The delay category, which groups flights based on their departure delay duration, serves as the classification target.\n",
    "\n",
    "3. **Classification Prediction Features**\n",
    "- The correlation matrix below details the relationships between the numerical features in the dataset and how they contribute to predicting the dep_delay (departure delay). \n",
    "    - dep_time: Correlation with arr_delay = 0.17 — While the departure time shows a small positive correlation, it suggests a weak connection to the arrival delay, but may still affect the model in certain contexts.\n",
    "    - sched_dep_time: Correlation with arr_delay = 0.18 — Scheduled departure time has a modest correlation, indicating that timing deviations from the schedule may influence arrival delays slightly.\n",
    "    - arr_time: Correlation with arr_delay = -0.15 — The arrival time has a weak negative correlation with arrival delay, which might indicate that later arrival times slightly reduce the delay in certain cases.\n",
    "    - sched_arr_time: Correlation with arr_delay = 0.10 — Scheduled arrival time has a slight positive correlation with arrival delay, suggesting that earlier or later scheduled times has some correlation with the final delay.\n",
    "    - hour: Correlation with arr_delay = 0.18 — The hour of the day has a modest positive correlation, indicating that certain times of day likely are associated with higher or lower delays, such as peak travel hours.\n",
    "- Additionally, the categorical features we selected (carrier, flight, tailnum, origin, dest) were based on the graph analysis we performed before beginning our classification due to their likely correlation with flight delays.\n",
    "\n",
    "**Preprocessing:**\n",
    "- **Categorical** Encoding: Features like carrier, flight, tailnum, origin, and dest were label-encoded to numerical representations for compatibility with the classification models.\n",
    "- **Scaling:** Numerical features were standardized using StandardScaler to ensure uniform feature scaling for algorithms sensitive to feature magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix (Balanced Flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'balanced_flights.csv' \n",
    "correlation_matrix = class_utils.analyze_flight_data(file_path)\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Dataset Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1: Distribution of Flight Delay Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysklearn import myutils \n",
    "file_path = \"flights.csv\"\n",
    "class_utils.visualize_flight_delays(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 presents a bar chart illustrating the distribution of flight delays across various categories. The x-axis categorizes delays into bins: On Time, 0-30 minutes, 30 minutes to 1 hour, 1-2 hours, 2-3 hours, 3-4 hours, and Over 4 hours. The y-axis represents the number of flights falling into each category.\n",
    "\n",
    "The chart reveals that the majority of flights operate on time, with the corresponding bar significantly taller than others. This indicates that the airline has a strong track record of punctuality. As the delay duration increases, the number of flights in each category steadily declines, suggesting that longer delays are less frequent. This is generally desirable for passenger satisfaction.\n",
    "\n",
    "However, to maintain accurate classification and avoid bias, it's essential to balance the selection of attributes from each delay category. Overemphasizing certain categories, such as on-time flights, could skew the model's ability to accurately predict and classify flights with longer delays. Therefore, a careful selection of attributes that represent the diversity of delay scenarios is necessary to ensure a robust and udtiased classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2: Distribution of Flight Delay Categories (Balanced Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"balanced_flights.csv\"\n",
    "class_utils.visualize_flight_delays_balanced(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2 presents a bar chart illustrating the distribution of flight delays across the same 6 categories as Figure 1. However, in the balanced dataset, each category has an even number (300) of instances. To improve the accuracy of classification models, it's crucial to consider the balanced distribution of data points across all delay categories. This will help the model learn the nuances of each category and avoid biases towards specific delay durations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 3: Average Flight Delay by Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"flights.csv\"\n",
    "class_utils.visualize_delays_by_airline(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3 presents a bar chart illustrating the average flight delay by airline for delayed flights only. The x-axis lists various airlines, while the y-axis represents the average delay in minutes.\n",
    "\n",
    "The chart reveals a significant variation in average delay times across different airlines. Some airlines have significantly higher average delays compared to others. This disparity suggests that certain airlines may have operational challenges or factors that contribute to more frequent or longer delays. This graph encourages us to include airline as a classification category to improve the accuracy of our delay prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 4 On Time vs. Delayed Flights by Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"flights.csv\"\n",
    "class_utils.on_time_vs_delayed_by_airline(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4 presents a bar chart illustrating the number of on-time and delayed flights by airline. The x-axis lists various airlines, while the y-axis represents the number of flights. Each airline is represented by two bars: one for on-time flights and one for delayed flights.\n",
    "\n",
    "The chart reveals significant variation in the proportion of on-time and delayed flights across different airlines. Some airlines have a higher number of delayed flights compared to on-time flights, while others exhibit the opposite trend. This figure provides even more evidence to suggest that airline impacts departure delay when paired with Figure 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 5: Average Flight Delay by Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"flights.csv\"\n",
    "class_utils.visualize_delays_by_time_of_day(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 5 clearly shows a pattern of flight delays varying across different times of the day. We can observe several key points:\n",
    "\n",
    "- Peak Delay Periods: The graph reveals distinct peak periods for flight delays. There is a significant increase in average delays around the early afternoon (13-15 hours) and late evening (18-20 hours). These periods likely correspond to peak travel times or periods with increased air traffic congestion.\n",
    "- Early Morning and Late Night Trends: Interestingly, the graph shows lower average delays during the early morning and late night hours. This could be attributed to reduced air traffic during these times, leading to fewer delays.\n",
    "- Consistent Pattern: The overall trend suggests a consistent pattern of delays throughout the day, with certain time slots being more prone to delays than others.\n",
    "\n",
    "Including time of day as one of our prediction attributes allows our model to leverage the information to identify high-risk periods and thus significantly enhance the accuracy and effectiveness of our flight delay prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 6: Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myutils.plot_correlation_matrix(\"balanced_flights.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in figure 6, we created and analyzed a correlation matrix to identify attributes that are strongly correlated with dep_delay, our target variable for predicting flight departure delays. This approach helps us understand the relationships between different variables and select the most relevant features for building an accurate predictive model.\n",
    "\n",
    "Strong Correlations:\n",
    "- sched_dep_time (0.19): This indicates that flights scheduled to depart later are more likely to experience delays. This is likely due to factors like increased air traffic congestion during peak hours.\n",
    "- hour (0.19): This suggests that certain times of the day might be more prone to delays. This could be related to peak travel times or weather patterns.\n",
    "- dep_time (0.18): Flights that actually depart later than scheduled are more likely to be delayed. This could be due to various reasons, such as maintenance issues or unexpected circumstances.\n",
    "- air_time (-0.04): This indicates that flights with shorter air times tend to have slightly lower departure delays. This could be due to factors like shorter routes or less complex flight paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results\n",
    "In this section, we detail the approach and performance of the classifiers developed for the task. The three classifiers evaluated are k-Nearest Neighbors (kNN), Naive Bayes, and Random Forest. Each classifier was assessed based on accuracy, error rate, precision, recall, and F1 score, with their respective confusion matrices used to evaluate their predictive ability across different categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping Data for Classification tasks using K-Fold cross-validation\n",
    "This code prepares the flight dataset by extracting relevant features and the target variable, then sets up the K-Fold cross-validation framework to evaluate the model's performance across 10 different splits. The performance metrics are stored for further analysis to identify the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('balanced_flights.csv')\n",
    "\n",
    "# Compute flight delay (in minutes, assuming sched_dep_time and dep_time are timestamps or integers)\n",
    "data['flight_delay'] = data['sched_dep_time'] - data['dep_time']\n",
    "\n",
    "# Extract meaningful features for predicting delays\n",
    "X = data[[\n",
    "    'year', 'month', 'day', 'hour', 'minute',  # Time-based features\n",
    "    'carrier', 'flight', 'tailnum',            # Operational features\n",
    "    'origin', 'dest', 'distance', 'air_time', # Location & flight characteristics\n",
    "    'dep_delay', 'sched_dep_time'             # Existing delay and timing\n",
    "]]\n",
    "\n",
    "# Target variable: flight delay\n",
    "y = data['flight_delay']\n",
    "\n",
    "# Initialize K-Fold cross-validation (10 splits)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Placeholder for performance metrics\n",
    "accuracies, error_rates, precisions, recalls, f1_scores, confusion_matrices = [], [], [], [], [], []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Flight Delay Data and Feature Scaling\n",
    "\n",
    "This code performs preprocessing tasks such as categorizing flight delays, label encoding categorical features, and scaling numerical features. The result is a dataset ready for training machine learning models, with features standardized and delays categorized for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (assuming `data` is a pandas DataFrame containing the provided sample data)\n",
    "data = pd.read_csv('balanced_flights.csv') \n",
    "\n",
    "# Define delay categories\n",
    "def categorize_delay(delay):\n",
    "    if delay <= 0:\n",
    "        return 0\n",
    "    elif 0 < delay <= 30:\n",
    "        return 1\n",
    "    elif 30 < delay <= 60:\n",
    "        return 2\n",
    "    elif 60 < delay <= 120:\n",
    "        return 3\n",
    "    elif 120 < delay <= 180:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# Map delays to categories\n",
    "data['delay_category'] = data['dep_delay'].apply(categorize_delay)\n",
    "\n",
    "# Convert categorical features to integers (label encoding)\n",
    "categorical_cols = ['carrier', 'flight', 'tailnum', 'origin', 'dest']  # List your categorical columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))  # Convert to string if necessary and apply label encoding\n",
    "    label_encoders[col] = le  # Store the encoder to use it later if needed\n",
    "\n",
    "# Prepare features (X) and labels (y)\n",
    "X = data[['dep_time', 'sched_dep_time', 'sched_arr_time', 'air_time', 'dest',\n",
    "          'carrier', 'hour']].fillna(0)\n",
    "\n",
    "y = data['delay_category'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN Performance Evaluation & Confusion Matrix\n",
    "This classifier was implemented using the kNN algorithm, which classifies an instance based on the majority class of its k nearest neighbors in the feature space. We experimented with different values of k to optimize performance, eventually selecting the best value based on cross-validation results. The classifier was trained on the features of the dataset, and predictions were made by calculating the Euclidean distance between test points and training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) \n",
    "y = np.array(y) \n",
    "\n",
    "# Initialize StratifiedKFold with k=10 (assuming myevaluation provides this utility)\n",
    "kf = myevaluation.stratified_kfold_split(X, y, n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics (accuracy, precision, recall, f1, confusion matrices, etc.)\n",
    "knn_accuracies, knn_precisions, knn_recalls, knn_f1s, knn_conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Initialize lists to gather true and predicted values across all folds\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Define the correct labels for the confusion matrix and metrics\n",
    "labels = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in kf:\n",
    "    knn_X_train, knn_X_test = X[train_index], X[test_index]\n",
    "    knn_y_train, knn_y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and fit MyKNeighborsClassifier\n",
    "    knn_model = MyKNeighborsClassifier()\n",
    "    knn_model.fit(knn_X_train.tolist(), knn_y_train.tolist())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    knn_y_pred = knn_model.predict(knn_X_test.tolist())\n",
    "    \n",
    "    # Calculate and store metrics for this fold\n",
    "    accuracy = myevaluation.accuracy_score(knn_y_test, knn_y_pred)\n",
    "    precision_score = myevaluation.binary_precision_score(knn_y_test, knn_y_pred, labels= labels)  # Multi-class precision\n",
    "    recall_score = myevaluation.binary_recall_score(knn_y_test, knn_y_pred, labels= labels)  # Multi-class recall\n",
    "    f1 = myevaluation.binary_f1_score(knn_y_test, knn_y_pred, labels= labels)  # Multi-class F1 score\n",
    "    confusion_matrix = myevaluation.confusion_matrix(knn_y_test, knn_y_pred, labels=labels)\n",
    "\n",
    "    # Store fold metrics\n",
    "    knn_accuracies.append(accuracy)\n",
    "    knn_precisions.append(precision_score)\n",
    "    knn_recalls.append(recall_score)\n",
    "    knn_f1s.append(f1)\n",
    "    knn_conf_matrices.append(confusion_matrix)\n",
    "    \n",
    "    # Collect all true and predicted labels for final confusion matrix\n",
    "    all_y_true.extend(knn_y_test)\n",
    "    all_y_pred.extend(knn_y_pred)\n",
    "\n",
    "# Calculate the final confusion matrix using all folds' predictions\n",
    "final_confusion_matrix = myevaluation.confusion_matrix(all_y_true, all_y_pred, labels=labels)\n",
    "matrix_with_totals = class_utils.calculate_confusion_matrix_totals(final_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"kNN Classifier Performance\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Accuracy: {np.mean(knn_accuracies):.2f}\")\n",
    "print(f\"Error: {1 - np.mean(knn_accuracies):.2f}\")\n",
    "print(f\"Precision: {np.mean(knn_precisions):.2f}\")\n",
    "print(f\"Recall: {np.mean(knn_recalls):.2f}\")\n",
    "print(f\"F1 Score: {np.mean(knn_f1s):.2f}\\n\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "class_utils.display_confusion_matrix(matrix_with_totals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Evaluation & Confusion Matrix\n",
    "For this classifier, we used the Naive Bayes approach, which assumes that the features are conditionally independent given the class label. This assumption simplifies the computation of class probabilities. The model was trained using the Multinomial Naive Bayes algorithm, which is well-suited for handling categorical features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) \n",
    "y = np.array(y) \n",
    "\n",
    "# Initialize StratifiedKFold with k=10\n",
    "kf = myevaluation.stratified_kfold_split(X, y, n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "nb_accuracies, nb_precisions, nb_recalls, nb_f1s, nb_conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Initialize lists to collect all true and predicted labels across all folds\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Define the correct labels for the confusion matrix and metrics\n",
    "labels = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# Loop over each fold in Stratified K-Fold\n",
    "for train_index, test_index in kf:\n",
    "    nb_X_train, nb_X_test = X[train_index], X[test_index]\n",
    "    nb_y_train, nb_y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and fit MyNaiveBayesClassifier\n",
    "    nb_model = MyNaiveBayesClassifier()\n",
    "    nb_model.fit(nb_X_train.tolist(), nb_y_train.tolist())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    nb_y_pred = nb_model.predict(nb_X_test.tolist())\n",
    "    \n",
    "    # Calculate and store metrics for this fold\n",
    "    accuracy = myevaluation.accuracy_score(nb_y_test, nb_y_pred)\n",
    "    error = 1 - accuracy\n",
    "    precision_score = myevaluation.binary_precision_score(nb_y_test, nb_y_pred, labels=labels)\n",
    "    recall_score = myevaluation.binary_recall_score(nb_y_test, nb_y_pred, labels=labels)\n",
    "    f1 = myevaluation.binary_f1_score(nb_y_test, nb_y_pred, labels=labels)\n",
    "    confusion_matrix = myevaluation.confusion_matrix(nb_y_test, nb_y_pred, labels=labels)\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    nb_accuracies.append(accuracy)\n",
    "    nb_precisions.append(precision_score)\n",
    "    nb_recalls.append(recall_score)\n",
    "    nb_f1s.append(f1)\n",
    "    nb_conf_matrices.append(confusion_matrix)\n",
    "\n",
    "    # Collect all true and predicted labels for final confusion matrix\n",
    "    all_y_true.extend(nb_y_test)\n",
    "    all_y_pred.extend(nb_y_pred)\n",
    "   \n",
    "\n",
    "# Calculate the final confusion matrix using all folds' predictions\n",
    "final_confusion_matrix = myevaluation.confusion_matrix(all_y_true, all_y_pred, labels=labels)\n",
    "matrix_with_totals = class_utils.calculate_confusion_matrix_totals(final_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"Naive Bayes Classifier Performance\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Accuracy: {np.mean(nb_accuracies):.2f}\")\n",
    "print(f\"Error: {1 - np.mean(nb_accuracies):.2f}\")\n",
    "print(f\"Precision: {np.mean(nb_precisions):.2f}\")\n",
    "print(f\"Recall: {np.mean(nb_recalls):.2f}\")\n",
    "print(f\"F1 Score: {np.mean(nb_f1s):.2f}\\n\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "class_utils.display_confusion_matrix(matrix_with_totals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Performance Evaluation & Confusion Matrix\n",
    "This ensemble method was implemented using a random selection of decision trees. Each tree is built by randomly selecting subsets of the features, and the final prediction is based on the majority vote of the trees. This method helps to reduce overfitting and provides robust performance in many classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assuming `data` is a pandas DataFrame containing the provided sample data)\n",
    "data = pd.read_csv('balanced_flights.csv') \n",
    "\n",
    "# Define delay categories\n",
    "def categorize_delay(delay):\n",
    "    if delay <= 0:\n",
    "        return 0\n",
    "    elif 0 < delay <= 30:\n",
    "        return 1\n",
    "    elif 30 < delay <= 60:\n",
    "        return 2\n",
    "    elif 60 < delay <= 120:\n",
    "        return 3\n",
    "    elif 120 < delay <= 180:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# Map delays to categories\n",
    "data['delay_category'] = data['arr_delay'].apply(categorize_delay)\n",
    "\n",
    "# Convert categorical features to integers (label encoding)\n",
    "categorical_cols = ['carrier', 'flight', 'tailnum', 'origin', 'dest']  # List your categorical columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))  # Convert to string if necessary and apply label encoding\n",
    "    label_encoders[col] = le  # Store the encoder to use it later if needed\n",
    "\n",
    "# Prepare features (X) and labels (y)\n",
    "X = data[['dep_time', 'sched_dep_time', 'dep_delay', 'arr_time', 'sched_arr_time', 'arr_delay', 'air_time', 'distance', 'dest',\n",
    "          'carrier', 'month', 'hour']].fillna(0)\n",
    "\n",
    "y = data['delay_category'].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Perform manual stratified K-fold\n",
    "n_splits = 10\n",
    "indices = np.arange(len(y))\n",
    "unique_classes, y_counts = np.unique(y, return_counts=True)\n",
    "folds = {i: [] for i in range(n_splits)}\n",
    "\n",
    "for cls in unique_classes:\n",
    "    cls_indices = indices[y == cls]\n",
    "    np.random.shuffle(cls_indices)\n",
    "    for i, index in enumerate(cls_indices):\n",
    "        folds[i % n_splits].append(index)\n",
    "\n",
    "fold_indices = [np.array(folds[i]) for i in range(n_splits)]\n",
    "\n",
    "# Metrics storage\n",
    "rf_accuracies, rf_precisions, rf_recalls, rf_f1s = [], [], [], []\n",
    "\n",
    "# Iterate through folds\n",
    "for i in range(n_splits):\n",
    "    test_indices = fold_indices[i]\n",
    "    train_indices = np.concatenate([fold_indices[j] for j in range(n_splits) if j != i])\n",
    "\n",
    "    rf_X_train, rf_X_test = X[train_indices], X[test_indices]\n",
    "    rf_y_train, rf_y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForest(n_estimators=10, max_depth=5)\n",
    "    rf_model.fit(rf_X_train, rf_y_train)\n",
    "\n",
    "    # Predictions\n",
    "    rf_y_pred = rf_model.predict(rf_X_test)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = np.sum(rf_y_test == rf_y_pred) / len(rf_y_test)\n",
    "    precision = precision_score(rf_y_test, rf_y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(rf_y_test, rf_y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(rf_y_test, rf_y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    # Store results\n",
    "    rf_accuracies.append(accuracy)\n",
    "    rf_precisions.append(precision)\n",
    "    rf_recalls.append(recall)\n",
    "    rf_f1s.append(f1)\n",
    "\n",
    "# Calculate the final confusion matrix using all folds' predictions\n",
    "final_confusion_matrix = myevaluation.confusion_matrix(all_y_true, all_y_pred, labels=labels)\n",
    "matrix_with_totals = class_utils.calculate_confusion_matrix_totals(final_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"Random Forest Classifier Performance\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Accuracy: {np.mean(rf_accuracies):.2f}\")\n",
    "print(f\"Error: {1 - np.mean(rf_accuracies):.2f}\")\n",
    "print(f\"Precision: {np.mean(rf_precisions):.2f}\")\n",
    "print(f\"Recall: {np.mean(rf_recalls):.2f}\")\n",
    "print(f\"F1 Score: {np.mean(rf_f1s):.2f}\\n\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "class_utils.display_confusion_matrix(matrix_with_totals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Classifier Performance:\n",
    "To evaluate the performance of each classifier, we used several standard metrics: accuracy, precision, recall, and F1 score. Accuracy measures the proportion of correct predictions, while precision and recall provide insight into how well the classifier performs on positive class predictions and the completeness of its predictions, respectively. The F1 score is the harmonic mean of precision and recall, providing a balanced measure when the class distribution is imbalanced. Additionally, we utilized a confusion matrix to visualize the true positive, false positive, true negative, and false negative predictions, which further helped in assessing the classifier’s performance across different classes.\n",
    "\n",
    "**Performance Results:**\n",
    "\n",
    "- k-Nearest Neighbors (kNN) performed the best overall, achieving an accuracy of 0.63, with a precision of 0.58, recall of 0.68, and an F1 score of 0.62. This classifier showed strong predictive ability, particularly in recognizing the positive classes, with relatively high recognition percentages across most classes in the confusion matrix.\n",
    "- Naive Bayes showed the weakest performance, with an accuracy of just 0.22, precision of 0.37, recall of 0.36, and an F1 score of 0.36. The confusion matrix indicated poor recognition of the true classes, with very low recognition percentages across all categories, indicating that Naive Bayes struggled to classify most instances correctly.\n",
    "- Random Forest provided moderate performance, with an accuracy of 0.43, precision of 0.48, recall of 0.42, and an F1 score of 0.43. The recognition percentages across classes were low, though it performed better than Naive Bayes.\n",
    "\n",
    "**Comparision and Conclusion**\n",
    "\n",
    "Based on the evaluation metrics, kNN outperformed the other two classifiers, with the highest accuracy, precision, recall, and F1 score, making it the best-performing model for this dataset. While Random Forest showed better performance than Naive Bayes, it still lagged behind kNN in all key metrics. Naive Bayes, on the other hand, performed poorly across all measures, making it the least suitable classifier for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this project, we worked with a large dataset consisting of 300,000 instances, with a significant number of \"on-time\" instances and an imbalanced class distribution, making the classification task challenging. To address this, we discretized the data and balanced it to ensure even amounts in each category, mitigating the impact of class imbalance on classifier performance.\n",
    "\n",
    "Next, we developed and evaluated three classifiers: k-Nearest Neighbors (kNN), Naive Bayes, and Random Forest. The kNN classifier outperformed the others with the highest accuracy, precision, recall, and F1 score, making it the most suitable model for this problem. Naive Bayes struggled with poor performance across all metrics, while Random Forest showed moderate performance, but performed worse than the kNN.\n",
    "\n",
    "To improve our results, we could continue to fine-tune the hyperparameters of the kNN, Random Forest, and Naive Bayes classifiers could help improve their performance. Another idea we have is to potentially explore simple neural networks to increase the accuracy of our predictions. Neural networks, particularly multi-layer perceptrons (MLPs), have the ability to model complex relationships between features, which can be beneficial to our dataset since it is  very large. Unlike traditional classifiers, like the ones we already deployed, neural networks can learn non-linear patterns and interactions between features that may not be easily captured by other models. Incorporating a simple neural network could allow the model to better understand the intricate structures in the data, leading to improved classification performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "Farzad Nekouei. \"Flight Data EDA to Preprocessing.\" Kaggle, https://www.kaggle.com/code/farzadnekouei/flight-data-eda-to-preprocessing.\n",
    "\n",
    "GeeksforGeeks. \"Random Forest Classifier using Scikit-learn.\" GeeksforGeeks, https://www.geeksforgeeks.org/random-forest-classifier-using-scikit-learn/.\n",
    "\n",
    "\"Neural Networks (Supervised) — scikit-learn 1.5 documentation.\" scikit-learn, https://scikit-learn.org/1.5/modules/neural_networks_supervised.html.\n",
    "\n",
    "OpenAI. \"ChatGPT.\" ChatGPT, https://chat.openai.com.\n",
    "\n",
    "\"RandomForestClassifier — scikit-learn 1.5 documentation.\" scikit-learn, https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
