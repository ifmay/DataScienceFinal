{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✈️ Flight Delay Classification ✈️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('balanced_flights.csv')\n",
    "\n",
    "# Compute flight delay (in minutes, assuming sched_dep_time and dep_time are timestamps or integers)\n",
    "data['flight_delay'] = data['sched_dep_time'] - data['dep_time']\n",
    "\n",
    "# Extract meaningful features for predicting delays\n",
    "X = data[[\n",
    "    'year', 'month', 'day', 'hour', 'minute',  # Time-based features\n",
    "    'carrier', 'flight', 'tailnum',            # Operational features\n",
    "    'origin', 'dest', 'distance', 'air_time', # Location & flight characteristics\n",
    "    'dep_delay', 'sched_dep_time'             # Existing delay and timing\n",
    "]]\n",
    "\n",
    "# Target variable: flight delay\n",
    "y = data['flight_delay']\n",
    "\n",
    "# Initialize K-Fold cross-validation (10 splits)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Placeholder for performance metrics\n",
    "accuracies, error_rates, precisions, recalls, f1_scores, confusion_matrices = [], [], [], [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assuming `data` is a pandas DataFrame containing the provided sample data)\n",
    "data = pd.read_csv('balanced_flights.csv') \n",
    "\n",
    "# Define delay categories\n",
    "def categorize_delay(delay):\n",
    "    if delay <= 0:\n",
    "        return 0\n",
    "    elif 0 < delay <= 30:\n",
    "        return 1\n",
    "    elif 30 < delay <= 60:\n",
    "        return 2\n",
    "    elif 60 < delay <= 120:\n",
    "        return 3\n",
    "    elif 120 < delay <= 180:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# Map delays to categories\n",
    "data['delay_category'] = data['dep_delay'].apply(categorize_delay)\n",
    "\n",
    "# Convert categorical features to integers (label encoding)\n",
    "categorical_cols = ['carrier', 'flight', 'tailnum', 'origin', 'dest']  # List your categorical columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))  # Convert to string if necessary and apply label encoding\n",
    "    label_encoders[col] = le  # Store the encoder to use it later if needed\n",
    "\n",
    "# Prepare features (X) and labels (y)\n",
    "X = data[['dep_time', 'sched_dep_time', 'sched_arr_time', 'air_time', 'dest',\n",
    "          'carrier', 'hour']].fillna(0)\n",
    "\n",
    "y = data['delay_category'].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN Performance Evaluation & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label must be specified for binary classification.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate and store metrics for this fold\u001b[39;00m\n\u001b[1;32m     33\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m myevaluation\u001b[38;5;241m.\u001b[39maccuracy_score(knn_y_test, knn_y_pred)\n\u001b[0;32m---> 34\u001b[0m precision_score \u001b[38;5;241m=\u001b[39m myevaluation\u001b[38;5;241m.\u001b[39mbinary_precision_score(knn_y_test, knn_y_pred, labels\u001b[38;5;241m=\u001b[39m labels)  \u001b[38;5;66;03m# Multi-class precision\u001b[39;00m\n\u001b[1;32m     35\u001b[0m recall_score \u001b[38;5;241m=\u001b[39m myevaluation\u001b[38;5;241m.\u001b[39mbinary_recall_score(knn_y_test, knn_y_pred, labels\u001b[38;5;241m=\u001b[39m labels)  \u001b[38;5;66;03m# Multi-class recall\u001b[39;00m\n\u001b[1;32m     36\u001b[0m f1 \u001b[38;5;241m=\u001b[39m myevaluation\u001b[38;5;241m.\u001b[39mbinary_f1_score(knn_y_test, knn_y_pred, labels\u001b[38;5;241m=\u001b[39m labels)  \u001b[38;5;66;03m# Multi-class F1 score\u001b[39;00m\n",
      "File \u001b[0;32m/home/DataScienceFinal/mysklearn/myevaluation.py:309\u001b[0m, in \u001b[0;36mbinary_precision_score\u001b[0;34m(y_true, y_pred, labels, pos_label)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision (for binary classification). The precision is the ratio tp / (tp + fp)\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    where tp is the number of true positives and fp the number of false positives.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    The precision is intuitively the ability of the classifier not to label as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m        https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_label must be specified for binary classification.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# True positives: predicted as pos_label and actually are pos_label\u001b[39;00m\n\u001b[1;32m    311\u001b[0m tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m true, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(y_true, y_pred) \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m==\u001b[39m pos_label \u001b[38;5;129;01mand\u001b[39;00m true \u001b[38;5;241m==\u001b[39m pos_label)\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label must be specified for binary classification."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = np.array(X) \n",
    "y = np.array(y) \n",
    "\n",
    "# Initialize StratifiedKFold with k=10 (assuming myevaluation provides this utility)\n",
    "kf = myevaluation.stratified_kfold_split(X, y, n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics (accuracy, precision, recall, f1, confusion matrices, etc.)\n",
    "knn_accuracies, knn_precisions, knn_recalls, knn_f1s, knn_conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Initialize lists to gather true and predicted values across all folds\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Define the correct labels for the confusion matrix and metrics\n",
    "labels = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in kf:\n",
    "    knn_X_train, knn_X_test = X[train_index], X[test_index]\n",
    "    knn_y_train, knn_y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and fit MyKNeighborsClassifier\n",
    "    knn_model = MyKNeighborsClassifier()\n",
    "    knn_model.fit(knn_X_train.tolist(), knn_y_train.tolist())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    knn_y_pred = knn_model.predict(knn_X_test.tolist())\n",
    "    \n",
    "    # Calculate and store metrics for this fold\n",
    "    accuracy = myevaluation.accuracy_score(knn_y_test, knn_y_pred)\n",
    "    precision_score = myevaluation.binary_precision_score(knn_y_test, knn_y_pred, labels= labels)  # Multi-class precision\n",
    "    recall_score = myevaluation.binary_recall_score(knn_y_test, knn_y_pred, labels= labels)  # Multi-class recall\n",
    "    f1 = myevaluation.binary_f1_score(knn_y_test, knn_y_pred, labels= labels)  # Multi-class F1 score\n",
    "    confusion_matrix = myevaluation.confusion_matrix(knn_y_test, knn_y_pred, labels=labels)\n",
    "\n",
    "    # Store fold metrics\n",
    "    knn_accuracies.append(accuracy)\n",
    "    knn_precisions.append(precision_score)\n",
    "    knn_recalls.append(recall_score)\n",
    "    knn_f1s.append(f1)\n",
    "    knn_conf_matrices.append(confusion_matrix)\n",
    "    \n",
    "    # Collect all true and predicted labels for final confusion matrix\n",
    "    all_y_true.extend(knn_y_test)\n",
    "    all_y_pred.extend(knn_y_pred)\n",
    "\n",
    "# Calculate the final confusion matrix using all folds' predictions\n",
    "final_confusion_matrix = myevaluation.confusion_matrix(all_y_true, all_y_pred, labels=labels)\n",
    "matrix_with_totals = myutils.calculate_confusion_matrix_totals(final_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "kNN Classifier Performance\n",
      "===========================================\n",
      "Accuracy: 0.63\n",
      "Error: 0.37\n",
      "Precision: 0.58\n",
      "Recall: 0.68\n",
      "F1 Score: 0.62\n",
      "\n",
      "Confusion Matrix:\n",
      "  Delayed    0    1    2    3    4    5    Total    Recognition %\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ---------------\n",
      "        0  204   89    6    1    0    0      300            68.00\n",
      "        1  118  140   39    3    0    0      300            46.67\n",
      "        2   30   80  142   46    2    0      300            47.33\n",
      "        3    3   12   59  187   39    0      300            62.33\n",
      "        4    0    0    2   51  209   38      300            69.67\n",
      "        5    0    0    1    5   47  247      300            82.33\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"kNN Classifier Performance\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Accuracy: {np.mean(knn_accuracies):.2f}\")\n",
    "print(f\"Error: {1 - np.mean(knn_accuracies):.2f}\")\n",
    "print(f\"Precision: {np.mean(knn_precisions):.2f}\")\n",
    "print(f\"Recall: {np.mean(knn_recalls):.2f}\")\n",
    "print(f\"F1 Score: {np.mean(knn_f1s):.2f}\\n\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "myutils.display_confusion_matrix(matrix_with_totals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Evaluation & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X) \n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y) \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize StratifiedKFold with k=10\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = np.array(X) \n",
    "y = np.array(y) \n",
    "\n",
    "# Initialize StratifiedKFold with k=10\n",
    "kf = myevaluation.stratified_kfold_split(X, y, n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "nb_accuracies, nb_precisions, nb_recalls, nb_f1s, nb_conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Initialize lists to collect all true and predicted labels across all folds\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Define the correct labels for the confusion matrix and metrics\n",
    "labels = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# Loop over each fold in Stratified K-Fold\n",
    "for train_index, test_index in kf:\n",
    "    nb_X_train, nb_X_test = X[train_index], X[test_index]\n",
    "    nb_y_train, nb_y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and fit MyNaiveBayesClassifier\n",
    "    nb_model = MyNaiveBayesClassifier()\n",
    "    nb_model.fit(nb_X_train.tolist(), nb_y_train.tolist())\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    nb_y_pred = nb_model.predict(nb_X_test.tolist())\n",
    "    \n",
    "    # Calculate and store metrics for this fold\n",
    "    accuracy = myevaluation.accuracy_score(nb_y_test, nb_y_pred)\n",
    "    error = 1 - accuracy\n",
    "    precision_score = myevaluation.binary_precision_score(nb_y_test, nb_y_pred, labels=labels)\n",
    "    recall_score = myevaluation.binary_recall_score(nb_y_test, nb_y_pred, labels=labels)\n",
    "    f1 = myevaluation.binary_f1_score(nb_y_test, nb_y_pred, labels=labels)\n",
    "    confusion_matrix = myevaluation.confusion_matrix(nb_y_test, nb_y_pred, labels=labels)\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    nb_accuracies.append(accuracy)\n",
    "    nb_precisions.append(precision_score)\n",
    "    nb_recalls.append(recall_score)\n",
    "    nb_f1s.append(f1)\n",
    "    nb_conf_matrices.append(confusion_matrix)\n",
    "\n",
    "    # Collect all true and predicted labels for final confusion matrix\n",
    "    all_y_true.extend(nb_y_test)\n",
    "    all_y_pred.extend(nb_y_pred)\n",
    "   \n",
    "\n",
    "# Calculate the final confusion matrix using all folds' predictions\n",
    "final_confusion_matrix = myevaluation.confusion_matrix(all_y_true, all_y_pred, labels=labels)\n",
    "matrix_with_totals = myutils.calculate_confusion_matrix_totals(final_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Naive Bayes Classifier Performance\n",
      "===========================================\n",
      "Accuracy: 0.22\n",
      "Error: 0.78\n",
      "Precision: 0.37\n",
      "Recall: 0.36\n",
      "F1 Score: 0.36\n",
      "\n",
      "Confusion Matrix:\n",
      "  Delayed    0    1    2    3    4    5    Total    Recognition %\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ---------------\n",
      "        0  109   45   44   32   30   40      300            36.33\n",
      "        1   43   67   51   54   52   33      300            22.33\n",
      "        2   49   51   46   66   48   40      300            15.33\n",
      "        3   35   49   53   52   51   60      300            17.33\n",
      "        4   40   50   36   55   53   66      300            17.67\n",
      "        5   24   39   46   51   73   67      300            22.33\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"Naive Bayes Classifier Performance\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Accuracy: {np.mean(nb_accuracies):.2f}\")\n",
    "print(f\"Error: {1 - np.mean(nb_accuracies):.2f}\")\n",
    "print(f\"Precision: {np.mean(nb_precisions):.2f}\")\n",
    "print(f\"Recall: {np.mean(nb_recalls):.2f}\")\n",
    "print(f\"F1 Score: {np.mean(nb_f1s):.2f}\\n\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "myutils.display_confusion_matrix(matrix_with_totals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Performance Evaluation & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: [0.6111111111111112, 0.6333333333333333, 0.6611111111111111, 0.6722222222222223, 0.6333333333333333, 0.6111111111111112, 0.6, 0.6722222222222223, 0.5777777777777777, 0.5944444444444444]\n",
      "Precisions: [0.6284058501725535, 0.6380461406045388, 0.6663845141786318, 0.6757498404479456, 0.6425925925925926, 0.619128602286497, 0.6045828159055819, 0.676750700280112, 0.5832846804111173, 0.5910270085916638]\n",
      "Recalls: [0.6111111111111112, 0.6333333333333333, 0.6611111111111111, 0.6722222222222222, 0.6333333333333334, 0.6111111111111112, 0.6, 0.6722222222222222, 0.5777777777777778, 0.5944444444444444]\n",
      "F1 Scores: [0.6136032350098509, 0.6334824955827353, 0.6604614162444622, 0.6701156689286204, 0.6301971326164875, 0.6106324405074463, 0.5975475147327222, 0.6727905100695136, 0.5797128707215145, 0.5921588568346935]\n",
      "Final Confusion Matrix:\n",
      " [[183  89  26   2   0   0]\n",
      " [ 86 146  56  12   0   0]\n",
      " [ 35  70 142  48   5   0]\n",
      " [  7  10  49 180  53   1]\n",
      " [  0   0   2  44 225  29]\n",
      " [  1   0   0   4  43 252]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Initialize StratifiedKFold with k=10\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "rf_accuracies, rf_precisions, rf_recalls, rf_f1s, rf_conf_matrices = [], [], [], [], []\n",
    "\n",
    "# Initialize lists to collect all true and predicted labels across all folds\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Define the correct labels for the confusion matrix and metrics\n",
    "labels = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    rf_X_train, rf_X_test = X[train_index], X[test_index]\n",
    "    rf_y_train, rf_y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize and fit RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(rf_X_train, rf_y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    rf_y_pred = rf_model.predict(rf_X_test)\n",
    "\n",
    "    # Calculate and store metrics for this fold\n",
    "    accuracy = accuracy_score(rf_y_test, rf_y_pred)\n",
    "    precision = precision_score(rf_y_test, rf_y_pred, labels=labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(rf_y_test, rf_y_pred, labels=labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(rf_y_test, rf_y_pred, labels=labels, average='macro', zero_division=0)\n",
    "    conf_matrix = confusion_matrix(rf_y_test, rf_y_pred, labels=labels)\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    rf_accuracies.append(accuracy)\n",
    "    rf_precisions.append(precision)\n",
    "    rf_recalls.append(recall)\n",
    "    rf_f1s.append(f1)\n",
    "    rf_conf_matrices.append(conf_matrix)\n",
    "\n",
    "    # Collect all true and predicted labels for final confusion matrix\n",
    "    all_y_true.extend(rf_y_test)\n",
    "    all_y_pred.extend(rf_y_pred)\n",
    "\n",
    "# Calculate the final confusion matrix using all folds' predictions\n",
    "final_confusion_matrix = confusion_matrix(all_y_true, all_y_pred, labels=labels)\n",
    "\n",
    "# Optionally add functionality to calculate totals for the confusion matrix if required\n",
    "# matrix_with_totals = myutils.calculate_confusion_matrix_totals(final_confusion_matrix)\n",
    "\n",
    "# Print or return the results as needed\n",
    "print(\"Accuracies:\", rf_accuracies)\n",
    "print(\"Precisions:\", rf_precisions)\n",
    "print(\"Recalls:\", rf_recalls)\n",
    "print(\"F1 Scores:\", rf_f1s)\n",
    "print(\"Final Confusion Matrix:\\n\", final_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Random Forest Classifier Performance\n",
      "===========================================\n",
      "Accuracy: 0.63\n",
      "Error: 0.37\n",
      "Precision: 0.63\n",
      "Recall: 0.63\n",
      "F1 Score: 0.63\n",
      "\n",
      "Confusion Matrix:\n",
      "  Delayed    0    1    2    3    4    5    Total    Recognition %\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ---------------\n",
      "        0  109   45   44   32   30   40      300            36.33\n",
      "        1   43   67   51   54   52   33      300            22.33\n",
      "        2   49   51   46   66   48   40      300            15.33\n",
      "        3   35   49   53   52   51   60      300            17.33\n",
      "        4   40   50   36   55   53   66      300            17.67\n",
      "        5   24   39   46   51   73   67      300            22.33\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"Random Forest Classifier Performance\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Accuracy: {np.mean(rf_accuracies):.2f}\")\n",
    "print(f\"Error: {1 - np.mean(rf_accuracies):.2f}\")\n",
    "print(f\"Precision: {np.mean(rf_precisions):.2f}\")\n",
    "print(f\"Recall: {np.mean(rf_recalls):.2f}\")\n",
    "print(f\"F1 Score: {np.mean(rf_f1s):.2f}\\n\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "myutils.display_confusion_matrix(matrix_with_totals, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0, 0, 4, 4, 0, 0, 4, 0, 0, 0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 4]\n",
      "Fold 2\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 5, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 0, 0, 0, 0, 0, 5, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 0, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 0, 0, 5, 5, 5, 0, 0]\n",
      "Fold 3\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 5, 1, 1, 5, 5, 1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 5, 1, 1, 5, 5, 5, 1, 1, 1, 1, 1, 5, 1, 1, 1, 5, 1, 5, 5, 1, 5, 1, 1, 1, 1, 1, 5, 5, 1, 5, 5, 1, 1, 5, 1, 5, 1, 5, 1, 1, 1, 5, 1, 1, 1, 1, 5, 1, 1, 5, 1, 5, 5, 5, 1, 1, 5, 5, 1, 1, 5, 1, 5, 1, 5, 1, 5, 1, 1, 5, 1, 1, 1, 1, 5, 1, 1, 1, 5, 5, 1, 5, 5, 5, 1]\n",
      "Fold 4\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 4, 0, 4, 0, 4, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 4, 0, 4, 4, 4, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4]\n",
      "Fold 5\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 4, 0, 0, 0, 4, 0, 4, 0, 4, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 4, 0, 4, 0, 4, 4, 0, 0, 0, 4, 0, 0, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 4, 0, 0, 0, 4, 0, 4, 0, 4, 4, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4]\n",
      "Fold 6\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 4, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 4, 0, 4, 0, 0, 4, 0, 0, 4, 4, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 4, 0, 0, 0, 0, 4, 4, 0, 4, 0, 4, 4, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 0, 4, 4, 4, 4, 0]\n",
      "Fold 7\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 0, 0, 4, 0, 0, 0, 4, 0, 4, 4, 0, 0, 0, 4, 0, 4, 0, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 0, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0]\n",
      "Fold 8\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 4, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 0, 0, 4, 4, 4, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 0, 4, 0, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 0, 4, 0, 0, 4, 4, 0]\n",
      "Fold 9\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 5, 5, 0, 0, 5, 5, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 5, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 0, 0, 0, 0, 5, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 0, 5, 0, 5, 0, 5, 0, 5, 0, 0, 5, 5, 0, 0, 0, 0, 0]\n",
      "Fold 10\n",
      "True Labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "Predicted Labels: [1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 4, 4, 4, 1, 4, 1, 4, 1, 4, 4, 1, 1, 4, 1, 1, 1, 4, 1, 4, 1, 1, 4, 4, 1, 1, 4, 4, 1, 1, 1, 1, 1, 4, 1, 1, 4, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 4, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 1, 4, 4, 1, 4, 4, 4, 4, 1, 4]\n",
      "Accuracies: [0.2388888888888889, 0.24444444444444444, 0.22777777777777777, 0.23333333333333334, 0.2222222222222222, 0.2222222222222222, 0.25, 0.26666666666666666, 0.2222222222222222, 0.20555555555555555]\n",
      "Precisions: [0.20863309352517986, 0.23478260869565218, 0.0, 0.2523364485981308, 0.2028985507246377, 0.20512820512820512, 0.24324324324324326, 0.26262626262626265, 0.22764227642276422, 0.0]\n",
      "Recalls: [0.9666666666666667, 0.9, 0.0, 0.9, 0.9333333333333333, 0.8, 0.9, 0.8666666666666667, 0.9333333333333333, 0.0]\n",
      "F1 Scores: [0.3431952662721894, 0.37241379310344824, 0.0, 0.3941605839416058, 0.33333333333333337, 0.326530612244898, 0.3829787234042553, 0.40310077519379856, 0.36601307189542487, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Convert features and labels to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Perform manual stratified K-fold\n",
    "n_splits = 10\n",
    "indices = np.arange(len(y))\n",
    "unique_classes, y_counts = np.unique(y, return_counts=True)\n",
    "folds = {i: [] for i in range(n_splits)}\n",
    "\n",
    "for cls in unique_classes:\n",
    "    cls_indices = indices[y == cls]\n",
    "    np.random.shuffle(cls_indices)\n",
    "    for i, index in enumerate(cls_indices):\n",
    "        folds[i % n_splits].append(index)\n",
    "\n",
    "fold_indices = [np.array(folds[i]) for i in range(n_splits)]\n",
    "\n",
    "# Metrics storage\n",
    "rf_accuracies, rf_precisions, rf_recalls, rf_f1s = [], [], [], []\n",
    "\n",
    "# Iterate through folds\n",
    "for i in range(n_splits):\n",
    "    test_indices = fold_indices[i]\n",
    "    train_indices = np.concatenate([fold_indices[j] for j in range(n_splits) if j != i])\n",
    "\n",
    "    rf_X_train, rf_X_test = X[train_indices], X[test_indices]\n",
    "    rf_y_train, rf_y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    # Train Random Forest\n",
    "    rf_model = MyRandomForestClassifier(n_estimators=1, max_depth=1)\n",
    "    rf_model.fit(rf_X_train, rf_y_train)\n",
    "\n",
    "    # Predictions\n",
    "    rf_y_pred = rf_model.predict(rf_X_test)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = np.sum(rf_y_test == rf_y_pred) / len(rf_y_test)\n",
    "    precision = myevaluation.binary_precision_score(rf_y_test, rf_y_pred)\n",
    "    recall = myevaluation.binary_recall_score(rf_y_test, rf_y_pred)\n",
    "    f1 = myevaluation.binary_f1_score(rf_y_test, rf_y_pred)\n",
    "\n",
    "    # Store results\n",
    "    rf_accuracies.append(accuracy)\n",
    "    rf_precisions.append(precision)\n",
    "    rf_recalls.append(recall)\n",
    "    rf_f1s.append(f1)\n",
    "\n",
    "    # Debugging outputs\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    print(\"True Labels:\", rf_y_test)\n",
    "    print(\"Predicted Labels:\", rf_y_pred)\n",
    "\n",
    "# Print final metrics\n",
    "print(\"Accuracies:\", rf_accuracies)\n",
    "print(\"Precisions:\", rf_precisions)\n",
    "print(\"Recalls:\", rf_recalls)\n",
    "print(\"F1 Scores:\", rf_f1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Random Forest Classifier Performance\n",
      "===========================================\n",
      "Accuracy: 0.97\n",
      "Error: 0.03\n",
      "Precision: 0.96\n",
      "Recall: 1.00\n",
      "F1 Score: 0.98\n",
      "\n",
      "Confusion Matrix:\n",
      "  Delayed    0    1    2    3    4    5    Total    Recognition %\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ---------------\n",
      "        0   39   10    4    5    4    4       66            59.09\n",
      "        1   12   15    9    9    2    1       48            31.25\n",
      "        2    4   10   14    3    2    4       37            37.84\n",
      "        3    6   10    1   21   10    9       57            36.84\n",
      "        4   10    2    5    9   11    8       45            24.44\n",
      "        5   11    1    5   11    8   11       47            23.40\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"Random Forest Classifier Performance\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Calculate and print average performance\n",
    "print(f\"Accuracy: {np.mean(rf_accuracies):.2f}\")\n",
    "print(f\"Error: {1 - np.mean(rf_accuracies):.2f}\")\n",
    "print(f\"Precision: {np.mean(rf_precisions):.2f}\")\n",
    "print(f\"Recall: {np.mean(rf_recalls):.2f}\")\n",
    "print(f\"F1 Score: {np.mean(rf_f1s):.2f}\\n\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "myutils.display_confusion_matrix(matrix_with_totals, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
